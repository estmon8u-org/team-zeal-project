# conf/config.yaml

# --- Data Parameters ---
data:
  raw_path: "data/raw/imagenette2-160.tgz"         # Path to the raw archive (relative to root)
  processed_path: "data/processed/imagenette2-160" # Path to extracted train/val folders
  img_size: 224                                    # Target image size for the model
  dataloader_workers: 2                            # Number of workers for DataLoader

# --- Model Parameters ---
model:
  name: "resnet18"       # Name of the model from timm
  pretrained: True       # Load ImageNet pre-trained weights
  num_classes: 10        # Number of classes in Imagenette

# --- Training Parameters ---
training:
  # freeze_layers: 2      # Optional: Number of initial stages to freeze (e.g., 0=none, 1, 2...) - uncomment if using
  epochs: 10             # Number of training epochs
  batch_size: 64         # Adjust based on GPU memory
  learning_rate: 1e-3
  weight_decay: 0.01
  optimizer: "AdamW"     # Options: AdamW, SGD, etc.
  scheduler: "CosineAnnealingLR" # Options: CosineAnnealingLR, StepLR, None
  label_smoothing: 0.1

  # --- Pytorch Profiler Parameters ---
  profiler:                  # New or updated section for PyTorch Profiler
      enabled: false           # Master switch: set to true to enable profiling for a run
      # Schedule parameters: Controls when and how long to profile
      wait: 1                  # Number of initial batches to wait before profiling starts in a cycle
      warmup: 1                # Number of warmup batches (results discarded to stabilize hardware timings)
      active: 3                # Number of batches to actively record profiling data
      repeat: 1                # Number of (wait, warmup, active) cycles to perform.
    # Set to 0 to profile for the entire `active` duration once, without repeating cycles.
                              # If > 0, profiler will cycle through wait, warmup, active for `repeat` times.

      # Output and trace parameters
      log_dir: "pytorch_profiler_logs" # Subdirectory within Hydra's output directory for trace files
      export_chrome_trace: true  # Essential for viewing with TensorBoard or Perfetto UI

      # Optional detail levels (can add significant overhead, use judiciously)
      record_shapes: false     # Records shapes of operator inputs
      profile_memory: false    # Tracks tensor memory allocations and deallocations
      with_stack: false        # Records source information (Python call stack) for operators

# --- Runtime Parameters ---
run:
  seed: 42               # Random seed for reproducibility
  device: "cuda"         # Target device: "cuda" or "cpu"

# --- Experiment Tracking (WandB) ---
wandb:
  project: "zeal-imagenette-drift"  # Your WandB project name
  entity: "emontel1-depaul-university" # Optional: Your WandB username or team name
  log_freq: 100                   # Log metrics every N batches


# --- Hydra Settings (Defaults are usually fine) ---
hydra:
  run:
    # Output directory pattern: outputs/YYYY-MM-DD/HH-MM-SS
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    # Output directory pattern for multirun: multirun/YYYY-MM-DD/HH-MM-SS
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num} # Subdirectory for each job in a sweep
